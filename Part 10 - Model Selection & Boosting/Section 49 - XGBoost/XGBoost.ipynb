{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning A-Z: Section 39 XGBoost\n",
    "\n",
    "In this notebook we'll be using XGBoost to solve the same problem solved with the Artificial Neural Network (Churn prediction). First though, we'll cover a quick description of what XGBoost.\n",
    "\n",
    "XGBoost is a library that implements Gradient Tree Boosting and does so in a way that makes it both simple to use, fast to train, and highly performant. At the moment it is regularly one of the top performing algorithms in many data science competitions.\n",
    "\n",
    "Like Random Forest models, Gradient Tree Boosting is a type of ensemble learning using multiple trees to improve the performance of the model. However, unlike Random Forest, Gradient Tree Boosting does not create a random set of trees and average the output. Instead, GTB has an objective function which includes factors for both accuracy and model complexity and GTB judiciously add new trees to improve areas where the current ensemble performs poorly while keeping the model complexity low. GTB decides how to boost the model's performance (i.e. add trees) by looking at the gradient (where the model can improve most) of the objective function. This is where the name comes from.\n",
    "\n",
    "The problem we'll be solving with XGBoost will be one of trying to determine which users are likely to stop using a particular bank (churn). In this case we'll create a geodemographic model from a sample of data the bank collected about it's customers and try to identify who is likely to leave the bank.\n",
    "\n",
    "## Step 1 Import and Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Libraries for fast linear algebra and array manipulation\n",
    "import pandas as pd # Import and manage datasets\n",
    "from plotly import __version__ as py__version__\n",
    "import plotly.express as px # Libraries for ploting data\n",
    "import plotly.graph_objects as go # Libraries for ploting data\n",
    "from sklearn import __version__ as skl__version__\n",
    "from sklearn.model_selection import train_test_split # Library to split data into training and test sets.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # Libraries to do encoding of categorical variables\n",
    "from sklearn.compose import ColumnTransformer # Library to transform only certain columns/features at a time\n",
    "from sklearn.preprocessing import StandardScaler # Library to do feature scaling\n",
    "from sklearn.metrics import confusion_matrix #Function for computing the confusion matrix\n",
    "from sklearn.model_selection import cross_val_score # Function for doing K-Fold Cross Validation\n",
    "from sklearn.model_selection import GridSearchCV # Library for doing Grid Search\n",
    "from xgboost import __version__ as xgb__version__\n",
    "from xgboost import XGBClassifier #XGBoost library for doing classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library versions used in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.16.4\n",
      "Pandas: 0.25.1\n",
      "Plotly: 4.0.0\n",
      "Scikit-learn: 0.21.2\n",
      "XGBoost Verion: 0.90\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ' + np.__version__)\n",
    "print('Pandas: ' + pd.__version__)\n",
    "print('Plotly: ' + py__version__)\n",
    "print('Scikit-learn: ' + skl__version__)\n",
    "print('XGBoost Verion: ' + xgb__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def LoadData():\n",
    "    dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "    return dataset\n",
    "\n",
    "dataset = LoadData()\n",
    "print(dataset.head(3))\n",
    "print()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset contains 14 columns. However, not all of them are useful for out model. Only the columns listed below will actually be useful:\n",
    "* CreditScore\n",
    "* Geography\n",
    "* Gender\n",
    "* Age\n",
    "* Tenure (How long the person has been a customer)\n",
    "* Balance\n",
    "* NumOfProducts (How many of the bank's products does the customer use)\n",
    "* HasCrCard\n",
    "* IsActiveMember\n",
    "* Estimated Salary\n",
    "\n",
    "Using the data in these columns we'll try to predict the value in the *Exited* column to determine if a user will leave the bank soon or not.\n",
    "\n",
    "You'll see in a moment that some of these columns are categorical variables that we'll need to encode to work properly. Also there does not appear to be any missing data in this data set.\n",
    "\n",
    "## Step 2. Split and Encode the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,3:-1].values # All the columns except the last are features\n",
    "y = dataset.iloc[:,-1].values # The last column is the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split the data into dependent and independent datasets we need to encode the categorical variables in the independent variables.\n",
    "\n",
    "We'll use One-Hot encoding on both gender and country to encode the categorical data. Don't forget to remove one of the new columns from the one-hot encoded categorical variables to avoid the dummy variable trap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 1.0 0.0 ... 0 1 112542.58]\n",
      " [0.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [0.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [1.0 0.0 1.0 ... 1 0 92888.52]\n",
      " [0.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "columntransformer = ColumnTransformer([\n",
    "    ('Country_Category', OneHotEncoder(drop='first'), [1]),\n",
    "    ('Gender_Category', OneHotEncoder(drop='first'), [2])],\n",
    "    remainder = 'passthrough')\n",
    "X = np.array(columntransformer.fit_transform(X))\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split the data into test and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = XGBClassifier(n_estimators = 100)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Model Performance\n",
    "Evaluate the performance of the model on the test data that was held back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1545   62]\n",
      " [ 212  181]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the confusion matrix using a single evaluation of the model, we have achieved an accuracy of 97%. Next we'll compare against K-Fold Cross Validation\n",
    "\n",
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.39%\n",
      "86.89%\n",
      "85.89%\n",
      "85.52%\n",
      "86.88%\n",
      "86.75%\n",
      "87.36%\n",
      "84.61%\n",
      "86.11%\n",
      "85.73%\n",
      "Average Accuracy: 86.31%\n",
      "Accuracy Standard Deviation: 0.85%\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "for accuracy in accuracies:\n",
    "    print(f'{accuracy*100:0.2f}%')\n",
    "\n",
    "print(f'Average Accuracy: {accuracies.mean()*100:0.2f}%')\n",
    "print(f'Accuracy Standard Deviation: {accuracies.std()*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run 10-Fold Cross Validation on the model, we see that our average accuracy 86% and it typically varies by about 1%. This result matches closely and even slightly outperforms what we were able to obtain with our ANN. Below we'll see if we can improve the performance of our model using a grid search.\n",
    "\n",
    "### Grid Search\n",
    "For Grid Search we need a dictionary of parameters to evaluate the model at. In our case we are interested in looking at one set of parameters with a linear model and a second set of parameters with a nonlinear model, so we'll use two parameter dictionaries in a list to keep the parameter sets different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2160 candidates, totalling 10800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3848 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5384 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6248 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8168 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9224 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10344 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10800 out of 10800 | elapsed: 21.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 86.37%\n",
      "Best Parameters:\n",
      "\tgamma: 0.01\n",
      "\tlearning_rate: 0.33\n",
      "\tmax_delta_step: 0\n",
      "\tmax_depth: 3\n",
      "\tmin_child_weight: 10\n",
      "\tn_estimators: 50\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\n",
    "    'n_estimators':[50,100,500],\n",
    "    'max_depth':[3,5,7],\n",
    "    'learning_rate':[0,.33,.66,1],\n",
    "    'gamma':[1,0.5,0.01],\n",
    "    'min_child_weight':[1,2,5,10],\n",
    "    'max_delta_step':[0,1,2,5,10]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 5, iid = False, n_jobs = -1, verbose = 3)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Accuracy: {grid_search.best_score_*100:0.2f}%')\n",
    "print('Best Parameters:')\n",
    "for key, val in grid_search.best_params_.items():\n",
    "    print(f'\\t{key}: {val}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the grid search above we really don't see any significant improvement over the default parameters. In this case is appears that the accuracy of our model may be limited by the quality and less than perfect correlations of our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
