{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning A-Z: Section 5 Multiple Linear Regression\n",
    "\n",
    "Multiple Linear Regression is similar to Simple Linear Regression from Section 4. The major difference is that instead of trying to find a linear relationship between a single independent variable and a single dependent variable, we are looking for a relationship between a linear combination of multiple independent variables and a single dependent variable. Like trying to fit a line to a cluster of datapoints in 3D+ space instead of 2D space.\n",
    "\n",
    "## Step 1 Import and Prepare the data.\n",
    "\n",
    "We'll use the template we created in Section 2 to import and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Libraries for fast linear algebra and array manipulation\n",
    "import pandas as pd # Import and manage datasets\n",
    "from plotly import __version__ as py__version__\n",
    "import plotly.express as px # Libraries for ploting data\n",
    "import plotly.graph_objects as go # Libraries for ploting data\n",
    "from sklearn import __version__ as skl__version__\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # Libraries to do encoding of categorical variables\n",
    "from sklearn.compose import ColumnTransformer # Library to transform only certain columns/features at a time\n",
    "from sklearn.model_selection import train_test_split # Library to split data into training and test sets.\n",
    "from sklearn.linear_model import LinearRegression # Library for creating Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library versions used in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.16.4\n",
      "Pandas: 0.25.1\n",
      "Plotly: 4.0.0\n",
      "Scikit-learn: 0.21.2\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ' + np.__version__)\n",
    "print('Pandas: ' + pd.__version__)\n",
    "print('Plotly: ' + py__version__)\n",
    "print('Scikit-learn: ' + skl__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def LoadData():\n",
    "    dataset = pd.read_csv('50_Startups.csv')\n",
    "    return dataset\n",
    "\n",
    "dataset = LoadData()\n",
    "print(dataset.head(3))\n",
    "print()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values # All the columns except the last are features\n",
    "y = dataset.iloc[:,-1].values # The last column is the dependent variable\n",
    "\n",
    "#Do the One-Hot encoding on our categorical data.\n",
    "columntransformer = ColumnTransformer(\n",
    "    [('Country_Category', OneHotEncoder(), [3])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "X = np.array(columntransformer.fit_transform(X))\n",
    "\n",
    "#Remove one of the new dummy variables to avoid the dummy vatiable trap.\n",
    "X = X [:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about the preprocessing:\n",
    "* We skipped the following sections of preprocessing:\n",
    "  * Missing Data - The dataset is complete with no missing data\n",
    "  * Feature Scaling - The linear regression libraries used here do not require prescaled data\n",
    "* After One-Hot encoding the new columns are as follows:\n",
    "  1. California\n",
    "  2. Florida\n",
    "  3. New York\n",
    "* To avoid the Dummy Variable Trap (i.e. Multicollinearity) we removed the first column (California) Hence we are left with the following independent variables:\n",
    "  1. Florida\n",
    "  2. New York\n",
    "  3. R&D Spend\n",
    "  4. Administration\n",
    "  5. Marketing Spend\n",
    "\n",
    "## Step 2: Fit a Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
