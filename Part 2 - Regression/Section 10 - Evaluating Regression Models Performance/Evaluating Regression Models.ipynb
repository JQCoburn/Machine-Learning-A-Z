{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning A-Z: Section 10 Evaluating Regression Model Performance\n",
    "\n",
    "When we look at how well a regression model performs, we often look at the r<sup>2</sup> value. The r<sup>2</sup> value is a measure of how much of the variability in the dependent variable can be explained by the value of the independent variable. The closer an r<sup>2</sup> value is to one, the more variability it explains. This sounds great, but r<sup>2</sup> has a hidden problem. Any random independent variable we add to the regression model will have some slight correlation to the dependent variable, and hence will improve the r<sup>2</sup> value on paper, but will just add dead weight (or worse reduce accuracy) of the model. \n",
    "\n",
    "An alternate to r<sup>2</sup> is adjusted-r<sup>2</sup>. Adjusted-r<sup>2</sup> is very similar to r<sup>2</sup> with the difference being a penalty factor which reduces adjusted-r<sup>2</sup> for each variable. Thus adjusted-r<sup>2</sup> can both increase or decrease with the addition of variables and in order to increase the benefit to performance (r<sup>2</sup>) must outweigh the penalty of adding an extra factor.\n",
    "\n",
    "In this section we'll write a function to do bi-directional elimiation stepwise regression. We'll use the p = 0.05 significance level for both adding and removing as well as looking at the adjusted-r<sup>2</sup> value.\n",
    "\n",
    "## Step 1 Import and Prepare the data.\n",
    "\n",
    "We'll use the template we created in Section 2 to import and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Libraries for fast linear algebra and array manipulation\n",
    "import pandas as pd # Import and manage datasets\n",
    "from plotly import __version__ as py__version__\n",
    "import plotly.express as px # Libraries for ploting data\n",
    "import plotly.graph_objects as go # Libraries for ploting data\n",
    "from sklearn import __version__ as skl__version__\n",
    "from sklearn.preprocessing import OneHotEncoder # Libraries to do encoding of categorical variables\n",
    "from sklearn.compose import ColumnTransformer # Library to transform only certain columns/features at a time\n",
    "from sklearn.model_selection import train_test_split # Library to split data into training and test sets.\n",
    "from sklearn.linear_model import LinearRegression # Library for creating Linear Regression Models\n",
    "from statsmodels import __version__ as statsmodels__version__\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library versions used in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.16.4\n",
      "Pandas: 0.25.1\n",
      "Plotly: 4.0.0\n",
      "Scikit-learn: 0.21.2\n",
      "Stats Models: 0.10.1\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ' + np.__version__)\n",
    "print('Pandas: ' + pd.__version__)\n",
    "print('Plotly: ' + py__version__)\n",
    "print('Scikit-learn: ' + skl__version__)\n",
    "print('Stats Models: ' + statsmodels__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def LoadData():\n",
    "    dataset = pd.read_csv('50_Startups.csv')\n",
    "    return dataset\n",
    "\n",
    "dataset = LoadData()\n",
    "print(dataset.head(3))\n",
    "print()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values # All the columns except the last are features\n",
    "y = dataset.iloc[:,-1].values # The last column is the dependent variable\n",
    "\n",
    "#Do the One-Hot encoding on our categorical data.\n",
    "columntransformer = ColumnTransformer(\n",
    "    [('Country_Category', OneHotEncoder(), [3])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "X = np.array(columntransformer.fit_transform(X))\n",
    "\n",
    "#Remove one of the new dummy variables to avoid the dummy variable trap.\n",
    "X = X [:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is prepared and ready for creating the model.\n",
    "\n",
    "We will create an outer loop to look through the unused variables and decide which is the best to add to the model and an inner to look through the used variables decide if we should remove any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 165349.2 136897.8]\n",
      " [0.0 162597.7 151377.59]\n",
      " [0.0 153441.51 101145.55]\n",
      " [1.0 144372.41 118671.85]\n",
      " [0.0 142107.34 91391.77]\n",
      " [1.0 131876.9 99814.71]\n",
      " [0.0 134615.46 147198.87]\n",
      " [0.0 130298.13 145530.06]\n",
      " [1.0 120542.52 148718.95]\n",
      " [0.0 123334.88 108679.17]\n",
      " [0.0 101913.08 110594.11]\n",
      " [0.0 100671.96 91790.61]\n",
      " [0.0 93863.75 127320.38]\n",
      " [0.0 91992.39 135495.07]\n",
      " [0.0 119943.24 156547.42]\n",
      " [1.0 114523.61 122616.84]\n",
      " [0.0 78013.11 121597.55]\n",
      " [1.0 94657.16 145077.58]\n",
      " [0.0 91749.16 114175.79]\n",
      " [1.0 86419.7 153514.11]\n",
      " [0.0 76253.86 113867.3]\n",
      " [1.0 78389.47 153773.43]\n",
      " [0.0 73994.56 122782.75]\n",
      " [0.0 67532.53 105751.03]\n",
      " [1.0 77044.01 99281.34]\n",
      " [0.0 64664.71 139553.16]\n",
      " [0.0 75328.87 144135.98]\n",
      " [1.0 72107.6 127864.55]\n",
      " [0.0 66051.52 182645.56]\n",
      " [1.0 65605.48 153032.06]\n",
      " [0.0 61994.48 115641.28]\n",
      " [1.0 61136.38 152701.92]\n",
      " [0.0 63408.86 129219.61]\n",
      " [0.0 55493.95 103057.49]\n",
      " [0.0 46426.07 157693.92]\n",
      " [1.0 46014.02 85047.44]\n",
      " [0.0 28663.76 127056.21]\n",
      " [0.0 44069.95 51283.14]\n",
      " [1.0 20229.59 65947.93]\n",
      " [0.0 38558.51 82982.09]\n",
      " [0.0 28754.33 118546.05]\n",
      " [0.0 27892.92 84710.77]\n",
      " [0.0 23640.93 96189.63]\n",
      " [1.0 15505.73 127382.3]\n",
      " [0.0 22177.74 154806.14]\n",
      " [1.0 1000.23 124153.04]\n",
      " [0.0 1315.46 115816.21]\n",
      " [0.0 0.0 135426.92]\n",
      " [1.0 542.05 51743.15]\n",
      " [0.0 0.0 116983.8]]\n"
     ]
    }
   ],
   "source": [
    "usedVariables = []\n",
    "unUsedVariables = [i for i in range(0,X.shape[1])]\n",
    "\n",
    "while unUsedVariables.len() > 0: # While there are still unused values and we haven't exited elswhere, look for the best value to add.\n",
    "    bestIndex = -1\n",
    "    bestPValue = 1\n",
    "    bestAdjR2 = -1\n",
    "    #look through the variables and find the one to add that most improves the model\n",
    "    for index in range(0, unUsedVariables.len()):\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
