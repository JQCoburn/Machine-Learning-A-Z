{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning A-Z: Section 10 Evaluating Regression Model Performance\n",
    "\n",
    "When we look at how well a regression model performs, we often look at the r<sup>2</sup> value. The r<sup>2</sup> value is a measure of how much of the variability in the dependent variable can be explained by the value of the independent variable. The closer an r<sup>2</sup> value is to one, the more variability it explains. This sounds great, but r<sup>2</sup> has a hidden problem. Any random independent variable we add to the regression model will have some slight correlation to the dependent variable, and hence will improve the r<sup>2</sup> value on paper, but will just add dead weight (or worse reduce accuracy) of the model. \n",
    "\n",
    "An alternate to r<sup>2</sup> is adjusted-r<sup>2</sup>. Adjusted-r<sup>2</sup> is very similar to r<sup>2</sup> with the difference being a penalty factor which reduces adjusted-r<sup>2</sup> for each variable. Thus adjusted-r<sup>2</sup> can both increase or decrease with the addition of variables and in order to increase the benefit to performance (r<sup>2</sup>) must outweigh the penalty of adding an extra factor.\n",
    "\n",
    "In this section we'll write a function to do bi-directional eliminatin stepwise regression. We'll use the p = 0.05 significance level for both adding and removing, but we'll also consider the effect to adjusted-r<sup>2</sup> value.\n",
    "\n",
    "## Step 1 Import and Prepare the data.\n",
    "\n",
    "We'll use the template we created in Section 2 to import and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Libraries for fast linear algebra and array manipulation\n",
    "import pandas as pd # Import and manage datasets\n",
    "from plotly import __version__ as py__version__\n",
    "import plotly.express as px # Libraries for ploting data\n",
    "import plotly.graph_objects as go # Libraries for ploting data\n",
    "from sklearn import __version__ as skl__version__\n",
    "from sklearn.preprocessing import OneHotEncoder # Libraries to do encoding of categorical variables\n",
    "from sklearn.compose import ColumnTransformer # Library to transform only certain columns/features at a time\n",
    "from sklearn.model_selection import train_test_split # Library to split data into training and test sets.\n",
    "from sklearn.linear_model import LinearRegression # Library for creating Linear Regression Models\n",
    "from statsmodels import __version__ as statsmodels__version__\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library versions used in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.16.4\n",
      "Pandas: 0.25.1\n",
      "Plotly: 4.0.0\n",
      "Scikit-learn: 0.21.2\n",
      "Stats Models: 0.10.1\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ' + np.__version__)\n",
    "print('Pandas: ' + pd.__version__)\n",
    "print('Plotly: ' + py__version__)\n",
    "print('Scikit-learn: ' + skl__version__)\n",
    "print('Stats Models: ' + statsmodels__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def LoadData():\n",
    "    dataset = pd.read_csv('50_Startups.csv')\n",
    "    return dataset\n",
    "\n",
    "dataset = LoadData()\n",
    "print(dataset.head(3))\n",
    "print()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [0.0 0.0 162597.7 151377.59 443898.53]]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:,:-1].values # All the columns except the last are features\n",
    "y = dataset.iloc[:,-1].values # The last column is the dependent variable\n",
    "\n",
    "#Do the One-Hot encoding on our categorical data.\n",
    "columntransformer = ColumnTransformer(\n",
    "    [('Country_Category', OneHotEncoder(), [3])],\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "X = np.array(columntransformer.fit_transform(X))\n",
    "\n",
    "#Remove one of the new dummy variables to avoid the dummy variable trap.\n",
    "X = X [:,1:]\n",
    "\n",
    "print(X[0:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is prepared and ready for creating the model.\n",
    "\n",
    "We will create an outer loop to look through the unused variables and decide which is the best to add to the model and an inner to look through the used variables decide if we should remove any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Columns: [2, 4]\n"
     ]
    }
   ],
   "source": [
    "usedVariables = []\n",
    "unUsedVariables = [i for i in range(0,X.shape[1])]\n",
    "\n",
    "currentAdjR2 = -1\n",
    "padd = 0.05\n",
    "premove = 0.05\n",
    "addedCol = True\n",
    "removedCol = True\n",
    "\n",
    "def evaluate_OLS_model(y, variables):\n",
    "    #fit and return the performance on an OLS model\n",
    "    #first add a constant\n",
    "    variables = np.append(values = variables.astype(float), arr = np.ones((len(variables),1)).astype(int), axis = 1)\n",
    "    #fit the model\n",
    "    ols_results = sm.OLS(endog = y, exog = variables).fit()\n",
    "    #return pvalues, rsquared\n",
    "    return (ols_results.pvalues.tolist()[1:], ols_results.rsquared_adj)\n",
    "\n",
    "while len(unUsedVariables) > 0 and (addedCol or removedCol) : # While there are still unused values and we haven't exited elswhere, look for the best value to add.\n",
    "    bestIndex = -1\n",
    "    bestPValue = 1\n",
    "    bestAdjR2 = -1\n",
    "    addedCol = False\n",
    "    removedCol = False\n",
    "    #look through the variables and find the one to add that most improves the model\n",
    "    for index in range(0, len(unUsedVariables)):\n",
    "        test_columns = usedVariables + [unUsedVariables[index]]\n",
    "        (pvals, r2) = evaluate_OLS_model(y, X[:,test_columns])\n",
    "        if (bestPValue > pvals[-1]):#is this the best p-value we've found?\n",
    "            bestIndex = index\n",
    "            bestPValue = pvals[-1]\n",
    "            bestAdjR2 = r2\n",
    "    \n",
    "    #Check to see if we should add the best column we found\n",
    "    if (bestPvalue < padd or bestAdjR2 > currentAdjR2): #The column is significant at the chosen level or it improves adjusted R2\n",
    "        usedVariables.append(unUsedVariables.pop(bestIndex))\n",
    "        currentAdjR2 = bestAdjR2\n",
    "        addedCol = True\n",
    "    else: #No Column is significant at the chosen level or improves R2\n",
    "        break\n",
    "    \n",
    "    #Check to see if any variables should be removed, we can't test a model with less than 1 \n",
    "    while len(usedVariables) > 1:\n",
    "        (pvals, r2) = evaluate_OLS_model(y, X[:,usedVariables])\n",
    "        if(max(pvals) > premove):\n",
    "            #remove the worst column and see if the model is better. \n",
    "            worst_col = usedVariables.pop(pvals.index(max(pvals)))\n",
    "            (test_pvals, test_r2) = evaluate_OLS_model(y, X[:,usedVariables])\n",
    "            if(test_r2 >= r2): #the model is better without the worst column, remove it\n",
    "                unUsedVariables.append(worst_col)\n",
    "                removedCol = True\n",
    "            else: #the model is better with the worst column even though it doesn't meet the significance level\n",
    "                usedVariables.append(worst_col)\n",
    "                currentAdjR2 = r2\n",
    "                break\n",
    "        else:\n",
    "            #no p-values were large enough to be removed, stop iterating\n",
    "            currentAdjR2 = r2\n",
    "            break\n",
    "\n",
    "print(f'Final Model Columns: {usedVariables}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-directional elimination is an intersting way to create a model. You start by finding the independent variable the has the best correlation with the dependent variable and add it to the model. Then you find the next independent variable which when added the current model improves it the most. After every addition we check to see if we any independent variables should be removed. At first glance this appears to be redundent, why would a variable be removed if it was already important enough to get added. Consider the following example:\n",
    ">We have 3 potential columns to use in our model: [__A__, __B__, __C__]\n",
    ">__A__ by itself correlates better than either __B__ or __C__ by themselves\n",
    ">However, __B__ and __C__ together correlate better than __A__ and make __A__ redundant (No additional improvement to adjusted-R<sup>2</sup>\n",
    ">__A__ and __C__ together also correlate well and perform better than __A__ alone.\n",
    ">In this case the bi-directional elimination would first add __A__ to the model.\n",
    ">In the next iteration, __C__ would be added to the model.\n",
    ">Checking for columns to remove would show nothing needed removal.\n",
    ">In the next iteration, __B__ would be added to the model.\n",
    ">Now checking if anything needed removal would show that __A__ should be removed. \n",
    ">Once more through the checks would show that __A__ shouldn't be added and nothing else need removed.\n",
    ">Our final model result would be [__C__, __B__]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
